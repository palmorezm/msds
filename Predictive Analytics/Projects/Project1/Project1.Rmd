---
title: "Project 1"
author: "Group 3"
date: "6/19/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning=F, message=F)
```

## Introduction

Given an unknown data source with several groups, we attempt to predict the next 140 values of a times series data set based on 1622 entries provided on multiple events. Our predictions will be fine-tuned to reduce the mean absolute percentage error (MAPE) as much as possible. The packages we will be using and all associated code to produce the models can be found in the attached markdown file. The data with its first five rows, are shown below.  

```{r}
# Packages
library(tidyverse)
# Data source
data <- read.csv("https://raw.githubusercontent.com/palmorezm/msds/main/624/Projects/project1data.csv")
data <- data %>% 
  rename(SeriesInd = ï..SeriesInd) 
head(data, 5)
```

We create forecasts for two preselected variables within each of six predetermined groups. These groups are denoted S01, S02, S03, S04, S05, and S06 respectively. There are five variables within each group that we have to work with. They are Var01, Var02, Var03, Var05, and Var07 respectively. Our date variable ‘SeriesInd,’ is displayed in its numeric serial number form calculated with Excel. Although we do not know what the variables stand for, we can develop models to try and forecast their behavior. This chart contains a breakdown of which variables are forecast in each group.

```{r}
# Chart
varsbygroup <- data.frame(matrix(c("S01", "S02", "S03",
                                   "S04", "S05", "S06", 
                                   "Var01", "Var02", "Var05",
                                   "Var01", "Var02", "Var05",
                                   "Var02", "Var03", "Var07",
                                   "Var02", "Var03", "Var07"),
                                 nrow = 6, ncol=3))
colnames(varsbygroup) <- c("Group", "Variable1", "Variable2")
varsbygroup %>% 
  kbl(booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"), full_width = T)
# Grouping
S01 <- data %>% 
  filter(group == "S01")
S02 <- data %>% 
  filter(group == "S02")
S03 <- data %>% 
  filter(group == "S03")
S04 <- data %>% 
  filter(group == "S04")
S05 <- data %>% 
  filter(group == "S05")
S06 <- data %>% 
  filter(group == "S06")

# Imputation by function - missing something? lapply/sapply may work 
soximp <- function(df){
  for (i in colnames(df)){
    if (sum(is.na(df[[i]])) !=0){
      df[[i]][is.na(df[[i]])] <- median(df[[i]], na.rm=TRUE)
    }
  }
}

# Imputation loops for each group by median 
for (i in colnames(S01)){
  if (sum(is.na(S01[[i]])) != 0){
    S01[[i]][is.na(S01[[i]])] <- median(S01[[i]], na.rm = TRUE)
  } 
}
for (i in colnames(S02)){
  if (sum(is.na(S02[[i]])) != 0){
    S02[[i]][is.na(S02[[i]])] <- median(S02[[i]], na.rm = TRUE)
  } 
}
for (i in colnames(S03)){
  if (sum(is.na(S03[[i]])) != 0){
    S03[[i]][is.na(S03[[i]])] <- median(S03[[i]], na.rm = TRUE)
  } 
}
for (i in colnames(S04)){
  if (sum(is.na(S04[[i]])) != 0){
    S04[[i]][is.na(S04[[i]])] <- median(S04[[i]], na.rm = TRUE)
  } 
}
for (i in colnames(S05)){
  if (sum(is.na(S05[[i]])) != 0){
    S05[[i]][is.na(S05[[i]])] <- median(S05[[i]], na.rm = TRUE)
  } 
}
for (i in colnames(S06)){
  if (sum(is.na(S06[[i]])) != 0){
    S06[[i]][is.na(S06[[i]])] <- median(S06[[i]], na.rm = TRUE)
  } 
}
```

Before we begin, the data is filtered to extract each time series by group. This isolates the Var01, Var02, Var03, Var05, and Var07 variables associated with groups S01, S02, and so on. Then, with each group and its respective variables’ behavior isolated, we clean and adjust the data to make use of it in the analysis. Once we determine the most appropriate models to forecast the proper variable in each group, we evaluate the results of our predictions. Our final forecasts are captured in the excel spreadsheet attached. 

## Analysis
### Subset S01, S02, S03 from the provided data.
Subset Var01 and Var 02 from S01.
Subset Var02 and Var 03 from S02.
Subset Var05 and Var 07 from S03.
```{r}

library(fpp2)

#S01
S01<-subset(data, group == "S01", select = c(SeriesInd, Var01, Var02))%>%
  mutate(date=as.Date(SeriesInd, origin = "1905-01-01"))
summary(S01)

# Subset Var01 and Var02 from S01.
S01_Var01<-S01 %>%select(Var01)
S01_Var01<-S01_Var01[1:1625,]


S01_Var02<-S01 %>%select(Var02)
S01_Var02<-S01_Var02[1:1625,]


#S02
S02<-subset(data, group == "S02", select = c(SeriesInd, Var02, Var03))%>%
  mutate(date=as.Date(SeriesInd, origin = "1905-01-01"))
summary(S02)

# Subset Var02 and Var03 from S02.
S02_Var02<-S02 %>%select(Var02)
S02_Var02<-S02_Var02[1:1625,]


S02_Var03<-S02 %>%select(Var03)
S02_Var03<-S02_Var03[1:1625,]



#S03
S03<-subset(data, group == "S03", select = c(SeriesInd, Var05, Var07))%>%
  mutate(date=as.Date(SeriesInd, origin = "1905-01-01"))
summary(S03)

# Subset Var05 and Var07 from S03.
S03_Var05<-S03 %>%select(Var05)
S03_Var05<-S03_Var05[1:1625,]


S03_Var07<-S03 %>%select(Var07)
S03_Var07<-S03_Var07[1:1625,]



```


### Clean NA from the subset data with imputeTS
```{r}
library(imputeTS)
# Summarize the subset data.

summary(S01_Var01)
summary(S01_Var02)
summary(S02_Var02)
summary(S02_Var03)
summary(S03_Var07)
summary(S03_Var05)

# according to the summary of subsets, 
# S01_Var01 has 5 NAs
# S01_Var02 has 3 NAs
# S02_Var02 has 3 NAs
# S02_Var03 has 7 NAs
# S03_Var07 has 7 NAs
# S03_Var05 has 7 NAs

# Using Kalman Smoothing to impute NAs.
S01_Var01<-na_kalman(S01_Var01)
S01_Var02<-na_kalman(S01_Var02)
S02_Var02<-na_kalman(S02_Var02)
S02_Var03<-na_kalman(S02_Var03)
S03_Var05<-na_kalman(S03_Var05)
S03_Var07<-na_kalman(S03_Var07)

summary(S01_Var01)
summary(S01_Var02)
summary(S02_Var02)
summary(S02_Var03)
summary(S03_Var07)
summary(S03_Var05)

# NA  no longer exists
```


### Convert variables to time series.
```{r}
ts_S01_Var01<-ts(S01_Var01)
ts_S01_Var02<-ts(S01_Var02)
ts_S02_Var02<-ts(S02_Var02)
ts_S02_Var03<-ts(S02_Var03)
ts_S03_Var05<-ts(S03_Var05)
ts_S03_Var07<-ts(S03_Var07)

str(ts_S01_Var01)
str(ts_S01_Var02)
str(ts_S02_Var02)
str(ts_S02_Var03)
str(ts_S03_Var05)
str(ts_S03_Var07)

autoplot(ts_S01_Var01)
autoplot(ts_S01_Var02)
autoplot(ts_S02_Var02)
autoplot(ts_S02_Var03)
autoplot(ts_S03_Var05)
autoplot(ts_S03_Var07)
```



### Verify skewness and Outliers

```{r}
par(mfrow = c(1,2))
hist(ts_S01_Var01)
boxplot(ts_S01_Var01)

par(mfrow = c(1,2))
hist(ts_S01_Var02)
boxplot(ts_S01_Var02)

par(mfrow = c(1,2))
hist(ts_S02_Var02)
boxplot(ts_S02_Var02)

par(mfrow = c(1,2))
hist(ts_S02_Var03)
boxplot(ts_S02_Var03)

par(mfrow = c(1,2))
hist(ts_S03_Var05)
boxplot(ts_S03_Var05)

par(mfrow = c(1,2))
hist(ts_S03_Var07)
boxplot(ts_S03_Var07)

```


Except for the S03, rest of the histgrams have right skewness, and Var02 and Var03 have some outliers. For V02, the outliers overlaps, it seems that they are not caused by mistake. It is more likely caused by shock. on the other hand, the Var03 has one point of outlier. Therefore, we assume the outlier from Var03 is caused by mistake.We use tsclean() function to get rid ofthe outlier from Var03.

```{r}
ts_S02_Var03<-tsclean(ts_S02_Var03)

boxplot(ts_S02_Var03) # the outlier from Var03 is cleaned.
```

### Seasonality
ndiffs test for ts_S01_Var01.
```{r}

ndiffs(ts_S01_Var01)
ts_S01_Var01%>%diff()%>%ndiffs()


```
The ndiffs test tells that ts_S01_Var01 requires 1 difference.


ndiffs test for ts_S01_Var02.
```{r}
ndiffs(ts_S01_Var02)
ts_S01_Var02%>%diff()%>%ndiffs()

```


ndiffs test for ts_S02_Var02.
```{r}
ndiffs(ts_S02_Var02)
ts_S02_Var02%>%diff()%>%ndiffs()



```


ndiffs test for ts_S02_Var03.
```{r}
ndiffs(ts_S02_Var03)
ts_S02_Var02%>%diff()%>%ndiffs()


```

ndiffs test for ts_S03_Var05.
```{r}
ndiffs(ts_S03_Var05)
ts_S03_Var05%>%diff()%>%ndiffs()


```

ndiffs test for ts_S03_Var07.
```{r}
ndiffs(ts_S03_Var07)
ts_S03_Var07%>%diff()%>%ndiffs()


```




According to the ndiffs test, all the variables above require difference.


## Prediction

Build training data

```{r}
train0101<-window(ts_S01_Var01, end=as.integer(length(ts_S01_Var01)*0.7))
train0102<-window(ts_S01_Var02, end=as.integer(length(ts_S01_Var02)*0.7))
train0202<-window(ts_S02_Var02, end=as.integer(length(ts_S02_Var02)*0.7))
train0203<-window(ts_S02_Var03, end=as.integer(length(ts_S02_Var03)*0.7))
train0305<-window(ts_S03_Var05, end=as.integer(length(ts_S03_Var05)*0.7))
train0307<-window(ts_S03_Var07, end=as.integer(length(ts_S03_Var07)*0.7))
```


test set
```{r}
length(ts_S01_Var01)*0.3
```
We chose 30% of the variables as the test data.



### MAPE Value
```{r}
library(dplyr)
library(forecast)
AA_fit0101 <- train0101 %>% auto.arima(stepwise = FALSE, approximation =FALSE, seasonal = TRUE) %>% forecast(h=488)
AA_fit0102 <- train0102 %>% auto.arima(stepwise = FALSE, approximation =FALSE, seasonal = TRUE) %>% forecast(h=488)
AA_fit0202 <- train0202 %>% auto.arima(stepwise = FALSE, approximation =FALSE, seasonal = TRUE) %>% forecast(h=488)
AA_fit0203 <- train0203 %>% auto.arima(stepwise = FALSE, approximation =FALSE, seasonal = TRUE) %>% forecast(h=488)
AA_fit0305 <- train0305 %>% auto.arima(stepwise = FALSE, approximation =FALSE, seasonal = TRUE) %>% forecast(h=488)
AA_fit0307 <- train0307 %>% auto.arima(stepwise = FALSE, approximation =FALSE, seasonal = TRUE) %>% forecast(h=488)



mape0101<-accuracy(AA_fit0101,ts_S01_Var01)["Test set", "MAPE"]
mape0101

mape0102<-accuracy(AA_fit0102,ts_S01_Var02)["Test set","MAPE"]
mape0102

mape0202<-accuracy(AA_fit0202,ts_S02_Var02)["Test set", "MAPE"]
mape0202

mape0203<-accuracy(AA_fit0203,ts_S02_Var03)["Test set", "MAPE"]
mape0203

mape0305<-accuracy(AA_fit0305,ts_S03_Var05)["Test set", "MAPE"]
mape0101

mape0307<-accuracy(AA_fit0307,ts_S03_Var07)["Test set", "MAPE"]
mape0307
```


```{r}
AA0101<-auto.arima(ts_S01_Var01, stepwise = F, approximation = F, seasonal = T)
fcast0101<-forecast(AA0101,h=140)
plot(fcast0101)

AA0102<-auto.arima(ts_S01_Var02, stepwise = F, approximation = F, seasonal = T)
fcast0102<-forecast(AA0102,h=140)
plot(fcast0102)

AA0202<-auto.arima(ts_S02_Var02, stepwise = F, approximation = F, seasonal = T)
fcast0202<-forecast(AA0202,h=140)
plot(fcast0202)


AA0203<-auto.arima(ts_S02_Var03, stepwise = F, approximation = F, seasonal = T)
fcast0203<-forecast(AA0203,h=140)
plot(fcast0203)

AA0305<-auto.arima(ts_S03_Var05, stepwise = F, approximation = F, seasonal = T)
fcast0305<-forecast(AA0305,h=140)
plot(fcast0305)



AA0307<-auto.arima(ts_S03_Var07, stepwise = F, approximation = F, seasonal = T)
fcast0307<-forecast(AA0307,h=140)
plot(fcast0307)
```


```{r}
fcast0101
fcast0102
fcast0202
fcast0203
fcast0305
fcast0307
```








