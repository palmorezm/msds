---
title: "Project 2 in R"
subtitle: "DATA 624-01 Group 3"
author: "Z. Palmore, K. Popkin, K. Potter, C. Nan, J. Ramalingam"
date: "7/8/2021"
output: 
  word_document:
    toc: true
    highlight: tango
header-includes: 
- \newcommand{\bcenter}{\begin{center}}
- \newcommand{\ecenter}{\end{center}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=F)
```

# Summary



# Data Exploration

Data is loaded and all packages used throughout the report are noted. We view a random sample of the data below. It shows the randomly selected observations as the first, second, third, fourth, and fifth for each variable. 

```{r, eval=T, warning=F, message=F}
library(utils)
library(psych)
library(tidyverse)
library(corrplot)
library(ggcorrplot)
library(MASS)
library(caret)
library(flextable)
library(bestNormalize)
theme_set(theme_minimal())
ph <- read.csv(
  "https://raw.githubusercontent.com/palmorezm/msds/main/624/Projects/Project2/StudentData%20-%20TO%20MODEL.csv")
obs.sample <- as.data.frame(t(head(sample_n(ph[1:33], 5), 5)))
obs.sample <- as.data.frame(lapply(obs.sample[2:33,], 
function(x) round(as.numeric(as.character(x)),1)))
obs.sample <- rbind(ph$ï..Brand.Code, obs.sample)
obs.sample <- obs.sample %>% 
  mutate(Variable = colnames(ph)) %>%
  dplyr::select(Variable, X1, X2, X3, X4, X5)
flextable(obs.sample) %>% 
  theme_vanilla() %>% 
  set_table_properties(layout = "autofit")
```



We note a few interesting facts before exploring further. We notice that data is missing. These appear as empty spots on the table. It also appears that due to the conversion of spreadsheet formats from excel to csv when hosting the data, our first column variable name is legible but needs the "i.." symbol removed. None of the other 33 variables need to be renamed. Our target variable, PH, appears to be on a scale between 1 and 10, as it should be, while the others vary between roughly -100 (Mnf.Flow) and greater than 4000 (Filler.Speed). We take a closer look at these variables with some descriptive statistics.  



```{r, eval=T}
ph.desc <- ph %>% 
  describe() %>%
  mutate("pm" = round(((2571 - n)/2571)*100, 2), 
         obs = n, 
         med = median) %>% 
  round(digits = 1) %>% 
  mutate(var = colnames(ph)) %>%
  dplyr::select(var, obs, pm, mean, med,
                sd, min, max, skew, se)
flextable::flextable(ph.desc) %>% 
  theme_vanilla() %>% 
  set_table_properties(layout = "autofit")
```

In the header the abbreviations stand for observations (obs), percent missing (missing), median, mean, standard deviation, minimum, maximum, range, skew, and standard error. These are calculated for each variable. To get a better understanding of the target variable we are trying to make predictions for, we visualize the points as a scatterplot.       


```{r}
ph %>% 
  dplyr::select(PH, Oxygen.Filler) %>% 
  mutate(Index = 1:length(ph$PH)) %>% 
  ggplot(aes(Index, PH)) + 
  geom_point(aes(color = PH, alpha=.25)) + 
  geom_smooth(method = "loess", 
              color="goldenrod2", 
              lty = "solid", 
              fill = "yellow1")
```



```{r}
# 1st set of variables - excluding brand code (categorical)
ph[c(2:9,26)] %>%
  gather(variable, value, -PH) %>% 
  ggplot(., aes(value, PH)) + 
  ggtitle("Linearity of Values") + 
  geom_point(fill = "white",
             size=1, 
             shape=1, 
             color="light sky blue") + 
  geom_smooth(formula = y~x, 
              method = "lm", 
              size=1,
              se = TRUE,
              color = "grey24", 
              linetype = "dotdash", 
              alpha=0.25) + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) 
# 2nd set of variables
ph[c(10:17,26)] %>%
  gather(variable, value, -PH) %>% 
  ggplot(., aes(value, PH)) + 
  ggtitle("Linearity of Values") + 
  geom_point(fill = "white",
             size=1, 
             shape=1, 
             color="light sky blue") + 
  geom_smooth(formula = y~x, 
              method = "lm", 
              size=1,
              se = TRUE,
              color = "grey24", 
              lty = "dotdash", 
              alpha=0.25) + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) 
# 3rd set of variables 
ph[c(18:26)] %>%
  gather(variable, value, -PH) %>% 
  ggplot(., aes(value, PH)) + 
  ggtitle("Linearity of Values") + 
  geom_point(fill = "white",
             size=1, 
             shape=1, 
             color="light sky blue") + 
  geom_smooth(formula = y~x, 
              method = "lm", 
              size=1,
              se = TRUE,
              color = "grey24", 
              linetype = "dotdash", 
              alpha=0.25, 
              fill="white") + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) 
# last 8 variables
ph[c(27:33,26)] %>% 
  mutate(pH = PH) %>% 
  gather(variable, value, -PH) %>% 
  ggplot(., aes(value, PH)) + 
  ggtitle("Linearity of Values") + 
  geom_point(fill = "white",
             size=1, 
             shape=1, 
             color="light sky blue") + 
  geom_smooth(formula = y~x, 
              method = "lm", 
              size=1,
              se = TRUE,
              color = "grey24", 
              linetype = "dotdash", 
              alpha=0.25) + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) 
```



```{r}
ph %>%
  gather(variable, value) %>% 
  ggplot(., aes(value)) + 
  ggtitle("Linearity of Values") + 
  geom_histogram(stat="count", 
                 binwidth = 10, 
                 fill = "white", 
                 color="light sky blue") + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) +
  theme(axis.text.x = element_blank(), 
        axis.text.y = element_blank(), 
        plot.title = element_blank())
```


```{r}
# Tornado plots by variable?
ph %>% 
  gather(variable, value, -PH) %>% 
  ggplot(aes(variable, value)) + 
  geom_violin(trim = FALSE, scale="area", 
              aes(color=variable, fill=variable, alpha=0.15, )) + coord_flip() + 
  geom_boxplot(width=.05, shape=1, alpha=0.20, color="black", size=.5) + 
  theme(legend.position = "None", 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank(), axis.text.y = element_blank()) + 
  facet_wrap(~variable, scales = "free")
```




```{r}
ordered <- ph %>% 
  dplyr::select(where(is.numeric)) %>% 
  arrange() 
cors <- cor(ordered, use = "complete.obs")
round(cors, 2)
corrplot::corrplot(cors, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

p.mat <- ggcorrplot::cor_pmat(cors, sig.level = 0.05)
sum(p.mat > .05)
ggcorrplot(cors, "square", "lower", 
           colors = c("#6D9EC1", "white", "#E46726"), 
           outline.color = "white", 
           digits = 1, 
           p.mat=p.mat,
           hc.order = FALSE, 
           hc.method = "complete") + 
  coord_flip() + 
  labs(title = "Corrlation Matrix with Significance Label 0.05")
# Alternative
order <- ph %>% 
  dplyr::select(where(is.numeric)) %>%
  arrange() %>%  
  gather(variable, value) %>% 
  pivot_wider(id_cols = variable, names_from = variable, values_from = value) %>%
  unnest()
order <- order[,order(colnames(order),decreasing=TRUE)]
cors <- cor(order, use = "complete.obs")
p.mat <- ggcorrplot::cor_pmat(cors, sig.level = 0.05)
sum(p.mat > .05)
ggcorrplot(cors, "square", "lower", 
           colors = c("#6D9EC1", "white", "#E46726"), 
           outline.color = "white", 
           digits = 1, 
           p.mat=p.mat,
           hc.order = FALSE, 
           hc.method = "complete") + 
  coord_flip() + 
  labs(title = "Corrlation Matrix with Significance Label 0.05")
```


```{r}
# Function to calculate and set pointrange
xysdu <- function(x) {
   m <- mean(x)
   ymin <- m - sd(x)
   ymax <- m + sd(x)
   return(c(y = m, ymin = ymin, ymax = ymax))
}
# Full picture point range 
ph %>% 
  dplyr::select(where(is.numeric)) %>% 
  gather(variable, value) %>% 
  ggplot(aes(variable, value)) + coord_flip() +
  stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
  stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") + 
  theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (smaller)
ph %>% 
  dplyr::select(where(is.numeric)) %>% 
  dplyr::select(-MFR, -Filler.Speed, -Carb.Flow, -Mnf.Flow) %>% 
  gather(variable, value) %>% 
  ggplot(aes(variable, value)) + coord_flip() +
  stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
  stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") + 
  theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (Medium)
ph %>% 
  dplyr::select(where(is.numeric)) %>% 
  dplyr::select(MFR, Mnf.Flow) %>% 
  gather(variable, value) %>% 
  ggplot(aes(variable, value)) + coord_flip() +
  stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
  stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") + 
  theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (larger)
ph %>% 
  dplyr::select(where(is.numeric)) %>% 
  dplyr::select(Filler.Speed, Carb.Flow) %>% 
  gather(variable, value) %>% 
  ggplot(aes(variable, value)) + coord_flip() +
  stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
  stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") + 
  theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
```




# Data Preparation


```{r}
# replaces NA with median (given a removal of missing values in calculation)
for (i in colnames(ph)) {
  ph[[i]][is.na(ph[[i]])] <- median(ph[[i]], na.rm=TRUE)
}
sum(is.na(ph))
```



```{r}
# select numeric variables
ph.numerics <- ph %>% 
  dplyr::select(where(is.numeric))
# remove outliers based on IQR
for (i in colnames(ph.numerics)) {
  iqr <- IQR(ph.numerics[[i]])
  q <- quantile(ph.numerics[[i]], probs = c(0.25, 0.75), na.rm = FALSE)
  qupper <- q[2]+1.5*iqr
  qlower <- q[1]+1.5*iqr
  outlier_free <- subset(ph.numerics, ph.numerics[[i]] > (q[1] - 1.5*iqr) & ph.numerics[[i]] < (q[2]+1.5*iqr) )
}
ph.numerics <- outlier_free
# join outlier free numerics with categorical 
Brand.Code <- ph$ï..Brand.Code
df <- cbind(Brand.Code, ph.numerics)
sum(is.na(df$Brand.Code))
```


```{r}
# Produce recommended transformations
df.nums <- df %>% 
  dplyr::select(where(is.numeric))
best.norms <- df.nums[1:11,1:10]
for (i in colnames(df.nums)) {
  best.norms[[i]] <- bestNormalize(df.nums[[i]],
                                  allow_orderNorm = FALSE,
                                  out_of_sample =FALSE)
}
best.norms$Carb.Volume$chosen_transform
```



# Model Building


```{r}
model.pm <- lm(PH~.,df)
pm <- stepAIC(model.pm, trace = F, direction = "both")
p <- summary(pm)$call
pm <- lm(p[2], df)
summary(pm)
```



```{r}
model.ks <- lm(PH~., df)
summary(model.ks)
```




```{r}
data <- df %>% 
  dplyr::select(Brand.Code, 
                Carb.Volume,
                Fill.Ounces,
                PC.Volume,
                Carb.Temp,
                PSC, 
                PSC.Fill, 
                PSC.CO2,
                PH,
                Mnf.Flow, 
                Carb.Pressure1, 
                Fill.Pressure, 
                Hyd.Pressure2, 
                Hyd.Pressure3, 
                Filler.Level,
                Temperature, 
                Usage.cont,
                Carb.Flow,
                Density,
                Balling,
                Pressure.Vacuum, 
                Oxygen.Filler, 
                Bowl.Setpoint, 
                Pressure.Setpoint, 
                Alch.Rel,
                Balling.Lvl)
```



```{r}

nnetGrid <- expand.grid(.decay=c(0, 0.01, 0.1, 0.5, 0.9),
                        .size=c(1, 10, 15, 20),
                        .bag=FALSE)
nnetModel <- train(x = train,
                   y = train,
                   method = "avNNet",
                   tuneGrid = nnetGrid,
                   preProc = c("center", "scale"),
                   trace=FALSE,
                   linout=TRUE,
                   maxit=500)
# Neural net may take several minutes
nnetPred <- predict(nnetModel, newdata = testData$x)
```





```{r}
library(naniar)
miss_var_summary(data)
vis_miss(data, sort_miss = TRUE) 
```



```{r}
library(zoo)
library(naniar)
data<-na.locf(data,fromLast = TRUE)
is.na(data)


vis_miss(data, sort_miss = TRUE) 
str(data)
```



```{r}
# Split 70-30 training test
set.seed(1102)
index <- createDataPartition(data$PH, p = .7, 
                             list = FALSE, times = 1)
train <- data[index,]
test <- data[-index,]
```




Ridge Regression

```{r}
library(elasticnet)
trctrl<- trainControl(method="repeatedcv", number=3, repeats=2)

ridge <- caret::train(PH~., data=train, method="ridge", 
                trControl=trctrl)
ridgePred <- predict(ridge, newdata = test)
ridge_test<-data.frame(postResample(pred = ridgePred, obs = test$PH)) 
ridge_test

```



Random Forest
```{r}
library(party)
library(caret)
forest <- train(PH~., data=train, method="cforest", 
                trControl=trctrl,
                tuneLength =2)
forestPred <- predict(forest, newdata = test)
forest_test<-data.frame(postResample(pred = forestPred, obs = test$PH)) 
forest_test
```


Support Vector

```{r}
library(caret)
library(kernlab)
svm_grid <-  expand.grid(C = c(1,1000))
svm<-train(PH~., data = train, 
                 method = 'svmRadialCost', 
                 trControl = trctrl, 
                 tuneGrid = svm_grid)
svmPred <- predict(svm, newdata = test)
svm_test<-data.frame(postResample(pred = svmPred, obs = test$PH)) 
svm_test
```



# Model Selection


# Predictions


# Conclusion













































































