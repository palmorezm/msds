---
title: "Project 2 in R"
subtitle: "DATA 624-01 Group 3"
author: "Z. Palmore, K. Popkin, K. Potter, C. Nan, J. Ramalingam"
date: "7/8/2021"
output: 
  word_document:
    toc: true
    highlight: tango
header-includes: 
- \newcommand{\bcenter}{\begin{center}}
- \newcommand{\ecenter}{\end{center}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=F)
```

# Summary



# Data Exploration

Data is loaded and all packages used throughout the report are noted. We view a random sample of the data below. It shows the randomly selected observations as the first, second, third, fourth, and fifth for each variable. 

```{r, eval=T, warning=F, message=F}
library(utils)
library(psych)
library(tidyverse)
library(corrplot)
library(MASS)
library(caret)
library(flextable)
theme_set(theme_minimal())
ph <- read.csv(
  "https://raw.githubusercontent.com/palmorezm/msds/main/624/Projects/Project2/StudentData%20-%20TO%20MODEL.csv")
obs.sample <- as.data.frame(t(head(sample_n(ph[1:33], 5), 5)))
obs.sample <- as.data.frame(lapply(obs.sample[2:33,], 
function(x) round(as.numeric(as.character(x)),1)))
obs.sample <- rbind(ph$ï..Brand.Code, obs.sample)
obs.sample <- obs.sample %>% 
  mutate(Variable = colnames(ph)) %>%
  dplyr::select(Variable, X1, X2, X3, X4, X5)
flextable(obs.sample) %>% 
  theme_vanilla() %>% 
  set_table_properties(layout = "autofit")
```



We note a few interesting facts before exploring further. We notice that data is missing. These appear as empty spots on the table. It also appears that due to the conversion of spreadsheet formats from excel to csv when hosting the data, our first column variable name is legible but needs the "i.." symbol removed. None of the other 33 variables need to be renamed. Our target variable, PH, appears to be on a scale between 1 and 10, as it should be, while the others vary between roughly -100 (Mnf.Flow) and greater than 4000 (Filler.Speed). We take a closer look at these variables with some descriptive statistics.   



```{r, eval=T}
ph.desc <- ph %>% 
  describe() %>%
  mutate("pm" = round(((2571 - n)/2571)*100, 2), 
         obs = n, 
         med = median) %>% 
  round(digits = 1) %>% 
  mutate(var = colnames(ph)) %>%
  dplyr::select(var, obs, pm, mean, med,
                sd, min, max, skew, se)
flextable::flextable(ph.desc) %>% 
  theme_vanilla() %>% 
  set_table_properties(layout = "autofit")
```

In the header the abbreviations stand for observations (obs), percent missing (missing), median, mean, standard deviation, minimum, maximum, range, skew, and standard error. These are calculated for each variable. To get a better understanding of the target variable we are trying to make predictions for, we visualize the points as a scatterplot.       


```{r}
ph %>% 
  dplyr::select(PH, Oxygen.Filler) %>% 
  mutate(ValueIndex = 1:length(ph$PH)) %>% 
  ggplot(aes(PH, Oxygen.Filler)) + 
  geom_point(aes(color = Oxygen.Filler)) + 
  geom_smooth(method = "lm")
```



```{r}
ph %>%
  gather(variable, value, -PH) %>% 
  ggplot(., aes(value, PH)) + 
  ggtitle("Linearity of Values") + 
  geom_point(fill = "white",
             size=1, 
             shape=1, 
             color="light sky blue") + 
  geom_smooth(formula = y ~x, 
              method = "lm", 
              size=.1,
              se = TRUE,
              color = "black", 
              linetype = "line", 
              alpha=0.25) + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) +
  theme(axis.text.x = element_blank(), 
        axis.text.y = element_blank(), 
        plot.title = element_blank())
```


```{r}
ph %>%
  gather(variable, value) %>% 
  ggplot(., aes(value)) + 
  ggtitle("Linearity of Values") + 
  geom_histogram(stat="count", 
                 fill = "white",
             size=1, 
             shape=1, 
             color="light sky blue") + 
  geom_density() + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) +
  theme(axis.text.x = element_blank(), 
        axis.text.y = element_blank(), 
        plot.title = element_blank())
```


```{r}
ph %>%
  gather(variable, value, -PH) %>% 
  ggplot(., aes(value, PH)) + 
  ggtitle("Linearity of Values") + 
  geom_violin(fill = "white",
             color="light sky blue") + 
  facet_wrap(~variable, 
             scales ="free",
             ncol = 4) +
  theme(axis.text.x = element_blank(), 
        axis.text.y = element_blank(), 
        plot.title = element_blank())
```




```{r}
numerics <- ph %>% 
  dplyr::select(where(is.numeric)) 
res <- cor(numerics, use = "complete.obs")
round(res, 2)
corrplot::corrplot(res, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```




```{r}
ggplot() + geom_boxplot(aes(ph$PH))
```

# Data Preparation

```{r}
# replaces NA with median (given a removal of missing values in calculation)
for (i in colnames(ph)) {
  ph[[i]][is.na(ph[[i]])] <- median(ph[[i]], na.rm=TRUE)
}
sum(is.na(ph))
```



```{r}
# select numeric variables
ph.numerics <- ph %>% 
  dplyr::select(is.numeric)
# remove outliers based on IQR
for (i in colnames(ph.numerics)) {
  iqr <- IQR(ph.numerics[[i]])
  q <- quantile(ph.numerics[[i]], probs = c(0.25, 0.75), na.rm = FALSE)
  qupper <- q[2]+1.5*iqr
  qlower <- q[1]+1.5*iqr
  outlier_free <- subset(ph.numerics, ph.numerics[[i]] > (q[1] - 1.5*iqr) & ph.numerics[[i]] < (q[2]+1.5*iqr) )
}
ph.numerics <- outlier_free
# join outlier free numerics with categorical 
Brand.Code <- ph$ï..Brand.Code
df <- cbind(Brand.Code, ph.numerics)
sum(is.na(df$Brand.Code))
```


# Model Building


```{r}
model.pm <- lm(PH~.,df)
pm <- stepAIC(model.pm, trace = F, direction = "both")
p <- summary(pm)$call
pm <- lm(p[2], df)
summary(pm)
```



```{r}
model.ks <- lm(PH~., df)
summary(model.ks)
```




```{r}
data <- df %>% 
  dplyr::select(Brand.Code, 
                Carb.Volume,
                Fill.Ounces,
                PC.Volume,
                Carb.Temp,
                PSC, 
                PSC.Fill, 
                PSC.CO2,
                PH,
                Mnf.Flow, 
                Carb.Pressure1, 
                Fill.Pressure, 
                Hyd.Pressure2, 
                Hyd.Pressure3, 
                Filler.Level,
                Temperature, 
                Usage.cont,
                Carb.Flow,
                Density,
                Balling,
                Pressure.Vacuum, 
                Oxygen.Filler, 
                Bowl.Setpoint, 
                Pressure.Setpoint, 
                Alch.Rel,
                Balling.Lvl)
```






```{r}
library(naniar)
miss_var_summary(data)
vis_miss(data, sort_miss = TRUE) 
```



```{r}
library(zoo)
library(naniar)
data<-na.locf(data,fromLast = TRUE)
is.na(data)


vis_miss(data, sort_miss = TRUE) 
str(data)
```



```{r}
# Split 70-30 training test
set.seed(1102)
index <- createDataPartition(data$PH, p = .7, 
                             list = FALSE, times = 1)
train <- data[index,]
test <- data[-index,]
```




Ridge Regression

```{r}
library(elasticnet)
trctrl<- trainControl(method="repeatedcv", number=3, repeats=2)

ridge <- caret::train(PH~., data=train, method="ridge", 
                trControl=trctrl)
ridgePred <- predict(ridge, newdata = test)
ridge_test<-data.frame(postResample(pred = ridgePred, obs = test$PH)) 
ridge_test

```



Random Forest
```{r}
library(party)
library(caret)
forest <- train(PH~., data=train, method="cforest", 
                trControl=trctrl,
                tuneLength =2)
forestPred <- predict(forest, newdata = test)
forest_test<-data.frame(postResample(pred = forestPred, obs = test$PH)) 
forest_test
```


Support Vector

```{r}
library(caret)
library(kernlab)
svm_grid <-  expand.grid(C = c(1,1000))
svm<-train(PH~., data = train, 
                 method = 'svmRadialCost', 
                 trControl = trctrl, 
                 tuneGrid = svm_grid)
svmPred <- predict(svm, newdata = test)
svm_test<-data.frame(postResample(pred = svmPred, obs = test$PH)) 
svm_test
```



# Model Selection


# Predictions


# Conclusion













































































