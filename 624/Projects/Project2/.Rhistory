ggtitle("Linearity of Values") +
geom_histogram(stat="count",
binwidth = 10,
fill = "white",
color="light sky blue") +
facet_wrap(~variable,
scales ="free",
ncol = 4) +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
plot.title = element_blank())
# Function to calculate and set pointrange
xysdu <- function(x) {
m <- mean(x)
ymin <- m - sd(x)
ymax <- m + sd(x)
return(c(y = m, ymin = ymin, ymax = ymax))
}
# Full picture point range
ptrng.full <- ph %>%
dplyr::select(where(is.numeric)) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (smaller)
ptrng.small <- ph %>%
dplyr::select(where(is.numeric)) %>%
dplyr::select(-MFR, -Filler.Speed, -Carb.Flow, -Mnf.Flow) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (Medium)
ptrng.med <- ph %>%
dplyr::select(where(is.numeric)) %>%
dplyr::select(MFR, Mnf.Flow) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (larger)
ptrng.lrg <- ph %>%
dplyr::select(where(is.numeric)) %>%
dplyr::select(Filler.Speed, Carb.Flow) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
ggarrange(ptrng.small,
ggarrange(ptrng.lrg, ptrng.med, ncol = 1, labels = c("B", "C")), nrow = 1, labels = "A"
)
# Correlation Plot
order <- ph %>%
dplyr::select(where(is.numeric)) %>%
arrange() %>%
gather(variable, value) %>%
pivot_wider(id_cols = variable, names_from = variable, values_from = value) %>%
unnest()
order <- order[,order(colnames(order),decreasing=TRUE)]
cors <- cor(order, use = "complete.obs")
p.mat <- ggcorrplot::cor_pmat(cors, sig.level = 0.05)
sum(p.mat > .05)
ggcorrplot(cors, "square", "lower",
colors = c("#6D9EC1", "white", "#E46726"),
outline.color = "white",
digits = 1,
p.mat=p.mat,
hc.order = FALSE,
hc.method = "complete") +
coord_flip() +
labs(title = "Corrlation Matrix with Significance Label 0.05")
# Check for missing data patterns with mice
na.pattern.mice <- md.pattern(ph) # No clear pattern
# Double check with hist and plot
aggr(ph, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE,
labels=names(ph), cex.axis=.7,
gap=3, ylab=c("Histogram","Pattern"))
# Small amount missing - simple median will do
obs.missing.perc <-
(sum(ph.desc$obs) / (33*2571)*100)
# replaces NA with median (given a removal of missing values in calculation)
for (i in colnames(ph)) {
ph[[i]][is.na(ph[[i]])] <- median(ph[[i]], na.rm=TRUE)
}
# Confirm none are missing
sum(is.na(ph))
# select numeric variables
ph.numerics <- ph %>%
dplyr::select(where(is.numeric))
# remove outliers based on IQR
for (i in colnames(ph.numerics)) {
iqr <- IQR(ph.numerics[[i]])
q <- quantile(ph.numerics[[i]], probs = c(0.25, 0.75), na.rm = FALSE)
qupper <- q[2]+1.5*iqr
qlower <- q[1]+1.5*iqr
outlier_free <- subset(ph.numerics, ph.numerics[[i]] > (q[1] - 1.5*iqr) & ph.numerics[[i]] < (q[2]+1.5*iqr) )
}
ph.numerics <- outlier_free
# join outlier free numerics with categorical
Brand.Code <- ph$ï..Brand.Code
df <- cbind(Brand.Code, ph.numerics)
df.summary <- summary(df)
# Produce recommended transformations
df.nums <- df %>%
dplyr::select(where(is.numeric))
best.norms <- df.nums[1:11,1:10]
for (i in colnames(df.nums)) {
best.norms[[i]] <- bestNormalize(df.nums[[i]],
allow_orderNorm = FALSE,
out_of_sample =FALSE)
}
best.norms$Carb.Volume$chosen_transform
model.pm <- lm(PH~.,train)
# Split 70-30 training/test
set.seed(1102)
index <- createDataPartition(
df$PH, p = .7,
list = FALSE, times = 1)
train <- df[index,]
test <- df[-index,]
# Create trainx and y
trainx <- train %>%
dplyr::select(-PH)
trainy <- train$PH
testx <- test %>%
dplyr::select(-PH)
testy <- test$PH
# Produce recommended transformations
df.nums <- df %>%
dplyr::select(where(is.numeric))
best.norms <- df.nums[1:11,1:10]
for (i in colnames(df.nums)) {
best.norms[[i]] <- bestNormalize(df.nums[[i]],
allow_orderNorm = FALSE,
out_of_sample =FALSE)
}
best.norms$Carb.Volume$chosen_transform
library(utils)
library(psych)
library(pls)
library(tidyverse)
library(corrplot)
library(elasticnet)
library(ggcorrplot)
library(ggpubr)
library(party)
library(MASS)
library(mice)
library(mboost)
library(VIM)
library(rpart)
library(caret)
library(zoo)
library(naniar)
library(partykit)
library(flextable)
library(bestNormalize)
theme_set(theme_minimal())
set.seed(004)
ph <- read.csv(
"https://raw.githubusercontent.com/palmorezm/msds/main/624/Projects/Project2/StudentData%20-%20TO%20MODEL.csv")
obs.sample <- as.data.frame(t(head(sample_n(ph[1:33], 5), 5)))
obs.sample <- as.data.frame(lapply(obs.sample[2:33,],
function(x) round(as.numeric(as.character(x)),1)))
obs.sample <- rbind(ph$ï..Brand.Code, obs.sample)
obs.sample <- obs.sample %>%
mutate(Variable = colnames(ph)) %>%
dplyr::select(Variable, X1, X2, X3, X4, X5)
flextable(obs.sample) %>%
theme_vanilla() %>%
set_table_properties(layout = "autofit")
ph.desc <- ph %>%
describe() %>%
mutate("pm" = round(((2571 - n)/2571)*100, 2),
obs = n,
med = median) %>%
round(digits = 1) %>%
mutate(var = colnames(ph)) %>%
dplyr::select(var, obs, pm, mean, med,
sd, min, max, skew, se)
flextable::flextable(ph.desc) %>%
theme_vanilla() %>%
set_table_properties(layout = "autofit")
ph %>%
dplyr::select(PH, Oxygen.Filler) %>%
mutate(Index = 1:length(ph$PH)) %>%
ggplot(aes(Index, PH, color = PH, alpha=.01)) +
geom_point(aes()) +
geom_smooth(method = "loess",
color="goldenrod2",
lty = "solid",
fill = "yellow1") +
geom_smooth(method = "lm",
color="grey34",
lty = "dotted",
fill = "grey13") +
labs(subtitle = "PH Patterns by Position",
x = "Position", y = "PH") +
theme(legend.position = "none")
# Bounds estimates
cap99 <- (length(ph$PH) - 4) / length(ph$PH)
# 1st set of variables - excluding brand code (categorical)
ph[c(2:9,26)] %>%
gather(variable, value, -PH) %>%
ggplot(., aes(value, PH)) +
labs(
subtitle =
"Variable Relationships with Yield Set 1") +
geom_point(fill = "white",
size=1,
shape=1,
color="light sky blue") +
geom_smooth(formula = y~x,
method = "lm",
size=1,
se = TRUE,
color = "grey24",
linetype = "dotdash",
alpha=0.25) +
facet_wrap(~variable,
scales ="free",
ncol = 4) +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank())
# 2nd set of variables
ph[c(10:17,26)] %>%
gather(variable, value, -PH) %>%
ggplot(., aes(value, PH)) +
labs(
subtitle =
"Variable Relationships with Yield Set 2") +
geom_point(fill = "white",
size=1,
shape=1,
color="light sky blue") +
geom_smooth(formula = y~x,
method = "lm",
size=1,
se = TRUE,
color = "grey24",
lty = "dotdash",
alpha=0.25) +
facet_wrap(~variable,
scales ="free",
ncol = 4)
# 3rd set of variables
ph[c(18:26)] %>%
gather(variable, value, -PH) %>%
ggplot(., aes(value, PH)) +
labs(
subtitle =
"Variable Relationships with Yield Set 3") +
geom_point(fill = "white",
size=1,
shape=1,
color="light sky blue") +
geom_smooth(formula = y~x,
method = "lm",
size=1,
se = TRUE,
color = "grey24",
linetype = "dotdash",
alpha=0.25,
fill="white") +
facet_wrap(~variable,
scales ="free",
ncol = 4)
# last 8 variables
ph[c(27:33,26)] %>%
mutate(pH = PH) %>%
gather(variable, value, -PH) %>%
ggplot(., aes(value, PH)) +
labs(
subtitle =
"Variable Relationships with Yield Set 4") +
labs(subtitle = ) +
geom_point(fill = "white",
size=1,
shape=1,
color="light sky blue") +
geom_smooth(formula = y~x,
method = "lm",
size=1,
se = TRUE,
color = "grey24",
linetype = "dotdash",
alpha=0.25) +
facet_wrap(~variable,
scales ="free",
ncol = 4)
ph %>%
gather(variable, value) %>%
ggplot(., aes(value)) +
ggtitle("Linearity of Values") +
geom_histogram(stat="count",
binwidth = 10,
fill = "white",
color="light sky blue") +
facet_wrap(~variable,
scales ="free",
ncol = 4) +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
plot.title = element_blank())
# Function to calculate and set pointrange
xysdu <- function(x) {
m <- mean(x)
ymin <- m - sd(x)
ymax <- m + sd(x)
return(c(y = m, ymin = ymin, ymax = ymax))
}
# Full picture point range
ptrng.full <- ph %>%
dplyr::select(where(is.numeric)) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (smaller)
ptrng.small <- ph %>%
dplyr::select(where(is.numeric)) %>%
dplyr::select(-MFR, -Filler.Speed, -Carb.Flow, -Mnf.Flow) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (Medium)
ptrng.med <- ph %>%
dplyr::select(where(is.numeric)) %>%
dplyr::select(MFR, Mnf.Flow) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
# Similar point ranges (larger)
ptrng.lrg <- ph %>%
dplyr::select(where(is.numeric)) %>%
dplyr::select(Filler.Speed, Carb.Flow) %>%
gather(variable, value) %>%
ggplot(aes(variable, value)) + coord_flip() +
stat_summary(fun.data=xysdu, geom = "Pointrange", shape=16, size=.5, color="black") +
stat_summary(fun.y=median, geom="point", shape=16, size=2, color="red") +
theme(legend.position = "None", axis.title.x = element_blank(), axis.title.y = element_blank())
ggarrange(ptrng.small,
ggarrange(ptrng.lrg, ptrng.med, ncol = 1, labels = c("B", "C")), nrow = 1, labels = "A"
)
# Correlation Plot
order <- ph %>%
dplyr::select(where(is.numeric)) %>%
arrange() %>%
gather(variable, value) %>%
pivot_wider(id_cols = variable, names_from = variable, values_from = value) %>%
unnest()
order <- order[,order(colnames(order),decreasing=TRUE)]
cors <- cor(order, use = "complete.obs")
p.mat <- ggcorrplot::cor_pmat(cors, sig.level = 0.05)
sum(p.mat > .05)
ggcorrplot(cors, "square", "lower",
colors = c("#6D9EC1", "white", "#E46726"),
outline.color = "white",
digits = 1,
p.mat=p.mat,
hc.order = FALSE,
hc.method = "complete") +
coord_flip() +
labs(title = "Corrlation Matrix with Significance Label 0.05")
# Check for missing data patterns with mice
na.pattern.mice <- md.pattern(ph) # No clear pattern
# Double check with hist and plot
aggr(ph, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE,
labels=names(ph), cex.axis=.7,
gap=3, ylab=c("Histogram","Pattern"))
# Small amount missing - simple median will do
obs.missing.perc <-
(sum(ph.desc$obs) / (33*2571)*100)
# replaces NA with median (given a removal of missing values in calculation)
for (i in colnames(ph)) {
ph[[i]][is.na(ph[[i]])] <- median(ph[[i]], na.rm=TRUE)
}
# Confirm none are missing
sum(is.na(ph))
# select numeric variables
ph.numerics <- ph %>%
dplyr::select(where(is.numeric))
# remove outliers based on IQR
for (i in colnames(ph.numerics)) {
iqr <- IQR(ph.numerics[[i]])
q <- quantile(ph.numerics[[i]], probs = c(0.25, 0.75), na.rm = FALSE)
qupper <- q[2]+1.5*iqr
qlower <- q[1]+1.5*iqr
outlier_free <- subset(ph.numerics, ph.numerics[[i]] > (q[1] - 1.5*iqr) & ph.numerics[[i]] < (q[2]+1.5*iqr) )
}
ph.numerics <- outlier_free
# join outlier free numerics with categorical
Brand.Code <- ph$ï..Brand.Code
df <- cbind(Brand.Code, ph.numerics)
df.summary <- summary(df)
# Produce recommended transformations
df.nums <- df %>%
dplyr::select(where(is.numeric))
best.norms <- df.nums[1:11,1:10]
for (i in colnames(df.nums)) {
best.norms[[i]] <- bestNormalize(df.nums[[i]],
allow_orderNorm = FALSE,
out_of_sample =FALSE)
}
best.norms$Carb.Volume$chosen_transform
model.pm <- lm(PH~.,train)
pm <- stepAIC(model.pm,
trace = F,
direction = "both")
p <- summary(pm)$call
pm <- lm(p[2], df)
summary(pm)
model.ks <- lm(PH~., train)
summary(model.ks)
trctrl<- trainControl(method="repeatedcv",
number=3,
repeats=2)
model.rr <- caret::train(PH~., data=train,
method="ridge",
trControl=trctrl)
ridgePred <- predict(model.rr, newdata = test)
ridge_test <-data.frame(
postResample(pred = ridgePred,
obs = test$PH))
ridge_test
model.rr
model.glmb <- train(x = trainx,
y = trainy,
method = "glmboost",
preProcess = c("center", "scale"),
tuneLength = 10)
model.glmb
model.pls<- train(x = trainx,
y = trainy,
method = "pls",
preProcess = c("center", "scale"),
tuneLength = 10)
model.pls
marsGrid <- expand.grid(.degree=1:2,
.nprune=2:10)
model.mar <- train(x = trainx,
y = trainy,
method = "earth",
preProcess = c("center", "scale"),
tuneGrid = marsGrid)
model.mar
library(plotrix)
ctl <- trainControl(method='repeatedcv',
number=10,
repeats=3)
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry)
model.rf <- train(PH~.,
data=train,
method='rf',
tuneGrid=tunegrid,
preProcess = c("center", "scale"),
trControl=ctl)
model.rf
library(kernlab)
nnet_grid <- expand.grid(.decay =
c(0, 0.01, .1),
.size = c(1:10),
.bag = FALSE)
nnet_maxnwts <- 5 * ncol(train) + 5 + 1
nnet_model <- train(
Yield ~ ., data = train, method = "avNNet",
center = TRUE,
scale = TRUE,
tuneGrid = nnet_grid,
trControl = trainControl(method = "cv"),
linout = TRUE,
trace = FALSE,
MaxNWts = nnet_maxnwts,
maxit = 500
)
nnet_model <- train(
PH ~ ., data = train, method = "avNNet",
center = TRUE,
scale = TRUE,
tuneGrid = nnet_grid,
trControl = trainControl(method = "cv"),
linout = TRUE,
trace = FALSE,
MaxNWts = nnet_maxnwts,
maxit = 500
)
nnet_model
model.cforest <- train(PH~.,
data=train,
method="cforest",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength =2)
forestPred <- predict(model.cforest, newdata = test)
forest_test<-data.frame(postResample(pred = forestPred, obs = test$PH))
forest_test
getwd()
setwd("C:/GitHub/msds/624/Projects/Project2")
